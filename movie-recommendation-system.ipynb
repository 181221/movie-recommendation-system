{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import mean, min, max\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [],
   "source": [
    "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x7fb1813a45d0>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://192.168.100.108:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.5</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark-shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [],
   "source": [
    "df_movies = spark.read.load('/home/peder/dev/big-data/movie-recommendation-system/data/movies_metadata.csv',\n",
    "                           format=\"csv\",\n",
    "                           sep=\",\",\n",
    "                           inferSchema=\"true\",\n",
    "                           header=\"true\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- adult: string (nullable = true)\n",
      " |-- belongs_to_collection: string (nullable = true)\n",
      " |-- budget: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- homepage: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- imdb_id: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- overview: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- revenue: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- spoken_languages: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- tagline: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- video: string (nullable = true)\n",
      " |-- vote_average: string (nullable = true)\n",
      " |-- vote_count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movies.printSchema()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is 45572 rows by 24 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the dataset is {:d} rows by {:d} columns\".format(df_movies.count(), len(df_movies.columns)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498\n",
      "389\n",
      "985\n"
     ]
    }
   ],
   "source": [
    "print(df_movies.filter(col(\"vote_average\").isNull()).count())\n",
    "print(df_movies.filter(col(\"vote_count\").isNull()).count())\n",
    "print(df_movies.filter(col(\"overview\").isNull()).count())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "df_movies = df_movies.na.drop(subset=[\"vote_average\"])\n",
    "df_movies = df_movies.na.drop(subset=[\"vote_count\"])\n",
    "df_movies = df_movies.na.drop(subset=[\"overview\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [],
   "source": [
    "df_movies = df_movies.withColumn(\"vote_average\", df_movies[\"vote_average\"].cast(\"double\"))\n",
    "df_movies = df_movies.withColumn(\"vote_count\", df_movies[\"vote_count\"].cast(\"int\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [],
   "source": [
    "df_movies = df_movies.filter((df_movies.vote_average >=0) & (df_movies.vote_average<=10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      vote_average|\n",
      "+-------+------------------+\n",
      "|  count|             40786|\n",
      "|   mean| 5.612511975530867|\n",
      "| stddev|1.9231620784205472|\n",
      "|    min|               0.0|\n",
      "|    max|              10.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movies.select(['vote_average']).describe().show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|       vote_count|\n",
      "+-------+-----------------+\n",
      "|  count|            40760|\n",
      "|   mean|112.1123405299313|\n",
      "| stddev|490.1629388596058|\n",
      "|    min|                0|\n",
      "|    max|            12269|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movies.select(['vote_count']).describe().show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|overview                                                                                                                                                                                                                                                                                                       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movies.select(['overview']).show(truncate=False, n=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [],
   "source": [
    "def clean_text(df, column_name=\"content\"):\n",
    "    \"\"\"\n",
    "    This fucntion takes the raw text data and apply a standard NLP preprocessing pipeline consisting of the following steps:\n",
    "      - Text cleaning\n",
    "      - Tokenization\n",
    "      - Stopwords removal\n",
    "      - Stemming (Snowball stemmer)\n",
    "\n",
    "    parameter: dataframe\n",
    "    returns: the input dataframe along with the `cleaned_content` column as the results of the NLP preprocessing pipeline\n",
    "\n",
    "    \"\"\"\n",
    "    from pyspark.sql.functions import udf, col, lower, trim, regexp_replace, concat_ws\n",
    "    from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "    # Text preprocessing pipeline\n",
    "    print(\"***** Text Preprocessing Pipeline *****\\n\")\n",
    "\n",
    "    # 1. Text cleaning\n",
    "    print(\"# 1. Text Cleaning\\n\")\n",
    "    # 1.a Case normalization\n",
    "    print(\"1.a Case normalization:\")\n",
    "    lower_case_news_df = df.select(\"id\", lower(col(column_name)).alias(column_name))\n",
    "    lower_case_news_df.show(10)\n",
    "    # 1.b Trimming\n",
    "    print(\"1.b Trimming:\")\n",
    "    trimmed_news_df = lower_case_news_df.select(\"id\", trim(col(column_name)).alias(column_name))\n",
    "    trimmed_news_df.show(10)\n",
    "    # 1.c Filter out punctuation symbols\n",
    "    print(\"1.c Filter out punctuation:\")\n",
    "    no_punct_news_df = trimmed_news_df.select(\"id\", (regexp_replace(col(column_name), \"[^a-zA-Z\\\\s]\", \"\")).alias(column_name))\n",
    "    no_punct_news_df.show(10)\n",
    "    # 1.d Filter out any internal extra whitespace\n",
    "    print(\"1.d Filter out extra whitespaces:\")\n",
    "    cleaned_news_df = no_punct_news_df.select(\"id\", trim(regexp_replace(col(column_name), \" +\", \" \")).alias(column_name))\n",
    "\n",
    "    # 2. Tokenization (split text into tokens)\n",
    "    print(\"# 2. Tokenization:\")\n",
    "    tokenizer = Tokenizer(inputCol=column_name, outputCol=\"tokens\")\n",
    "    tokens_df = tokenizer.transform(cleaned_news_df)\n",
    "\n",
    "    print(\"# 3. Stopwords removal:\")\n",
    "    stopwords_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"terms\")\n",
    "    terms_df = stopwords_remover.transform(tokens_df)\n",
    "\n",
    "    print(\"# 4. Stemming:\")\n",
    "    stemmer = SnowballStemmer(language=\"english\")\n",
    "    stemmer_udf = udf(lambda tokens: [stemmer.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "    terms_stemmed_df = terms_df.withColumn(\"terms_stemmed\", stemmer_udf(\"terms\"))\n",
    "    \n",
    "    print(\"# 5. untokenize\")\n",
    "    terms_joined_df = terms_stemmed_df.withColumn(\"terms_join\", concat_ws(\" \", \"terms_stemmed\"))\n",
    "    return terms_joined_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col, lower, trim, regexp_replace, concat_ws\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "def cleanse_text(df):    \n",
    "    lower_df = df.withColumn(\"overview_lower\", lower(col(\"overview\")))\n",
    "    trim_df = lower_df.withColumn(\"overview_trim\", trim(col(\"overview_lower\")))\n",
    "    no_punct_df = trim_df.withColumn(\"overview_no_punct\", regexp_replace(col(\"overview_trim\"), \"[^a-zA-Z\\\\s]\", \"\"))\n",
    "    no_whitespace_df = no_punct_df.withColumn(\"overview_cleansed\", trim(regexp_replace(col(\"overview_no_punct\"), \" +\", \" \")))\n",
    "    return no_whitespace_df, \"overview_cleansed\"                  \n",
    "    \n",
    "def tokenize_text(df, column_name):\n",
    "    tokenizer = Tokenizer(inputCol=column_name, outputCol=\"tokens\")\n",
    "    return tokenizer.transform(df), \"tokens\"\n",
    "\n",
    "def stem_tokens(df, column_name):\n",
    "    stemmer = SnowballStemmer(language=\"english\")\n",
    "    stemmer_udf = udf(lambda tokens: [stemmer.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "    return df.withColumn(\"terms_stemmed\", stemmer_udf(column_name)), \"terms_stemmed\"\n",
    "\n",
    "def remove_stop_words(df, column_name):\n",
    "    stopwords_remover = StopWordsRemover(inputCol=column_name, outputCol=\"terms\")\n",
    "    return stopwords_remover.transform(df), 'terms'\n",
    "\n",
    "def concat_arr(df, column_name):\n",
    "    return  df.withColumn(\"corpus\", concat_ws(\" \", column_name))\n",
    "\n",
    "def cleaning_pipe(df):\n",
    "    df, column_name = cleanse_text(df)\n",
    "    df, column_name = tokenize_text(df, column_name)\n",
    "    df, column_name = remove_stop_words(df, column_name)\n",
    "    df, column_name = stem_tokens(df, column_name)\n",
    "    return df, column_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [],
   "source": [
    "#df_clean = clean_text(df_movies, 'overview')\n",
    "#df_clean\n",
    "#from pyspark.ml.feature import Tokenizer\n",
    "#tokenizer = Tokenizer(inputCol=\"overview\", outputCol=\"terms_stemmed\")\n",
    "#tokens_df = tokenizer.transform(df_movies)\n",
    "#df_clean= tokens_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [
    "df_clean, column_name = cleaning_pipe(df_movies)\n",
    "\n",
    "df_pandas = concat_arr(df_clean, column_name).toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|       terms_stemmed|\n",
      "+--------------------+\n",
      "|[led, woodi, andi...|\n",
      "|[sibl, judi, pete...|\n",
      "|[famili, wed, rei...|\n",
      "|[georg, bank, rec...|\n",
      "|[obsess, master, ...|\n",
      "|[ugli, duckl, und...|\n",
      "|[mischiev, young,...|\n",
      "|[intern, action, ...|\n",
      "|[jame, bond, must...|\n",
      "|[widow, us, presi...|\n",
      "|[lawyer, show, va...|\n",
      "|[outcast, halfwol...|\n",
      "|[allstar, cast, p...|\n",
      "|[morgan, adam, sl...|\n",
      "|[life, gambl, par...|\n",
      "|[rich, mr, dashwo...|\n",
      "|[ted, bellhop, fi...|\n",
      "|[summon, ashram, ...|\n",
      "|[veng, new, york,...|\n",
      "|[agoraphob, psych...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.select(column_name).show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [],
   "source": [
    "#df_clean.select('terms_join').show(truncate=False, n=2)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [],
   "source": [
    "def tf_idf_features(df):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    return vectorizer.fit_transform(df['corpus'])\n",
    "\n",
    "def cosine_similarity(df, index):\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    return cosine_similarity(df[index], df)[0] # score item in dataframe against all other records"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [],
   "source": [
    "tf_idf_matrix = tf_idf_features(df_pandas)\n",
    "df_pandas['tfidf'] = tf_idf_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [],
   "source": [
    "df_index = pd.Series(df_pandas.index, index=df_pandas['title']).drop_duplicates() # create index\n",
    "\n",
    "def sort_cos_score(matrix, df):\n",
    "    arr = []\n",
    "    for index, row in df.iterrows():\n",
    "        arr.append(matrix[index])\n",
    "    df['cosine_score'] = arr\n",
    "    return df.sort_values(by=['cosine_score'], ascending=False)\n",
    "\n",
    "def get_similar(title):\n",
    "    index = df_index[title]\n",
    "    cos_sim = cosine_similarity(tf_idf_matrix, index)\n",
    "    return sort_cos_score(cos_sim, df_pandas)['original_title'].head(10)\n",
    "    return False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [
    {
     "data": {
      "text/plain": "9120                                         Batman Begins\n19169    Batman Unmasked: The Psychology of the Dark Kn...\n17892              Batman: The Dark Knight Returns, Part 1\n32412                                    Batman: Bad Blood\n16292                                     Batman: Year One\n14023                           Batman: Under the Red Hood\n2771                          Batman: Mask of the Phantasm\n40352                             Batman Beyond: The Movie\n39300                                        Batman & Bill\n1197                                        Batman Returns\nName: original_title, dtype: object"
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar('Batman Begins')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [
    {
     "data": {
      "text/plain": "3679                                               Memento\n30153    The True Meaning of Pictures: Shelby Lee Adams...\n7275                                                  Novo\n14879                                              Ghajini\n28773                        Hunt for the Labyrinth Killer\n23311                                            Implanted\n29256                                             Amnesiac\n35342                                       Without Memory\n40657                                  La sangre iluminada\n20066                                           Open Grave\nName: original_title, dtype: object"
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar('Memento')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [
    {
     "data": {
      "text/plain": "16100                       The Avengers\n23078       Kingsman: The Secret Service\n11856    When Willie Comes Marching Home\n28516                               Waar\n24006            Avengers: Age of Ultron\n22022                            Plastic\n12218                 Echelon Conspiracy\n6217         A Woman Under the Influence\n29129             Drums Across the River\n4751                         Bad Company\nName: original_title, dtype: object"
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar('The Avengers')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [
    {
     "data": {
      "text/plain": "0                                           Toy Story\n13874                                     Toy Story 3\n2683                                      Toy Story 2\n22181                                       Small Fry\n9287                           The 40 Year Old Virgin\n21564                     Andy Hardy's Blonde Trouble\n26377                                      Hot Splash\n34590    Superstar: The Life and Times of Andy Warhol\n38380    Andy Peters: Exclamation Mark Question Point\n1823                                   Pretty in Pink\nName: original_title, dtype: object"
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar('Toy Story')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [
    {
     "data": {
      "text/plain": "4569                            Ice Age\n12505    Ice Age: Dawn of the Dinosaurs\n9766              Ice Age: The Meltdown\n40467                     Surviving Sid\n17296        Ice Age: Continental Drift\n13310                          The Thaw\n22812      Ice Age: A Mammoth Christmas\n11235                         10,000 BC\n40465               Мама для мамонтёнка\n18059                              龍在天涯\nName: original_title, dtype: object"
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar('Ice Age')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [],
   "source": [
    "# same in pyspark but get different scores since tf_idf is calculated differently\n",
    "from pyspark.ml.feature import HashingTF, CountVectorizer, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "cv = CountVectorizer(inputCol=column_name, outputCol=\"tf_features\", vocabSize=20000, minDF=.01, maxDF=.90)\n",
    "idf = IDF(inputCol=\"tf_features\", outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[cv, idf])\n",
    "features = pipeline.fit(df_clean)\n",
    "tf_idf_df = features.transform(df_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [],
   "source": [
    "@udf(\"long\")\n",
    "def num_nonzeros(v):\n",
    "    return v.numNonzeros()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total n. of zero-length vectors: 155\n"
     ]
    }
   ],
   "source": [
    "print(\"Total n. of zero-length vectors: {:d}\".\n",
    "      format(tf_idf_df.where(num_nonzeros(\"features\") == 0).count()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [],
   "source": [
    "tf_idf_df = tf_idf_df.where(num_nonzeros(\"features\") > 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total n. of zero-length vectors (after removal): 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total n. of zero-length vectors (after removal): {:d}\".\n",
    "      format(tf_idf_df.where(num_nonzeros(\"features\") == 0).count()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "data": {
      "text/plain": "40631"
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_df.select('features').count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- adult: string (nullable = true)\n",
      " |-- belongs_to_collection: string (nullable = true)\n",
      " |-- budget: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- homepage: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- imdb_id: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- overview: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- revenue: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- spoken_languages: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- tagline: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- video: string (nullable = true)\n",
      " |-- vote_average: double (nullable = true)\n",
      " |-- vote_count: integer (nullable = true)\n",
      " |-- overview_lower: string (nullable = true)\n",
      " |-- overview_trim: string (nullable = true)\n",
      " |-- overview_no_punct: string (nullable = true)\n",
      " |-- overview_cleansed: string (nullable = true)\n",
      " |-- tokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- terms: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- terms_stemmed: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- tf_features: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_idf_df.printSchema()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5721506761565958"
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cosine_similarity_vec(a, b):\n",
    "    return 1 - a.dot(b)/(a.norm(2)*b.norm(2))\n",
    "\n",
    "def cosine_similarity(id1, id2):\n",
    "    df_1 = tf_idf_df.select(\"features\").where(tf_idf_df.id == id1).first()\n",
    "    df_2 = tf_idf_df.select(\"features\").where(tf_idf_df.id == id2).first()\n",
    "    return cosine_similarity_vec(df_1.features, df_2.features)\n",
    "\n",
    "cosine_similarity(\"238\",\"240\") # toy story 1 and 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+\n",
      "|id   |title           |\n",
      "+-----+----------------+\n",
      "|862  |Toy Story       |\n",
      "|11597|Toys            |\n",
      "|25898|Babes in Toyland|\n",
      "+-----+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_idf_df.select([\"id\",\"title\"]).filter(lower(tf_idf_df.title).like('%toy%')).show(truncate=False,n=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+\n",
      "|id  |title       |\n",
      "+----+------------+\n",
      "|1124|The Prestige|\n",
      "+----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_idf_df.select([\"id\",\"title\"]).filter(lower(tf_idf_df.title).like('%the prestige%')).show(truncate=False, n=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [],
   "source": [
    "def cos_sim_dataset(movie_vec):\n",
    "    udf_func = udf(lambda df:str(cosine_similarity_vec(movie_vec.features, df)))\n",
    "    return tf_idf_df.withColumn(\"cosine_similarity\", udf_func(\"features\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|cosine_similarity |id   |\n",
      "+------------------+-----+\n",
      "|1.0               |862  |\n",
      "|1.0               |8844 |\n",
      "|0.9759698416687279|15602|\n",
      "|1.0               |11862|\n",
      "|1.0               |949  |\n",
      "+------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_vec_batman_forever = tf_idf_df.select(\"features\").where(tf_idf_df.id == \"414\").first()\n",
    "\n",
    "df_similarity = cos_sim_dataset(df_vec_batman_forever)\n",
    "    \n",
    "df_similarity.select([\"cosine_similarity\", \"id\"]).show(truncate=False, n=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [
    {
     "data": {
      "text/plain": "Row(title='Jumanji', id='8844', cosine_similarity='1.0')"
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_similarity.select([\"title\",\"id\", \"cosine_similarity\"]).where(df_movies.id == \"8844\").first()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [],
   "source": [
    "#df_movies.select([\"id\",\"title\"]).filter(lower(df_movies.title).like('%the godfather%')).show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [],
   "source": [
    "df_similarity = df_similarity.withColumn(\"cosine_similarity\", df_similarity[\"cosine_similarity\"].cast(\"double\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+--------------------+\n",
      "|cosine_similarity|    id|               title|\n",
      "+-----------------+------+--------------------+\n",
      "|              1.0| 60410|      Remote Control|\n",
      "|              1.0|379291|Justice League vs...|\n",
      "|              1.0|157005|Google and the Wo...|\n",
      "|              1.0| 75027|          Checkpoint|\n",
      "|              1.0| 36818|         Smorgasbord|\n",
      "|              1.0|250852|The Notorious Mr....|\n",
      "|              1.0|242631|     So This Is Love|\n",
      "|              1.0|154786|          Wavemakers|\n",
      "|              1.0|207178|The Lion and the ...|\n",
      "|              1.0| 34158|    The People Speak|\n",
      "|              1.0| 85231|The Lone Wolf Mee...|\n",
      "|              1.0|122544|   The Perfect House|\n",
      "|              1.0| 66060|            Vacation|\n",
      "|              1.0|257044|   Game For Vultures|\n",
      "|              1.0|372691|       White Bondage|\n",
      "|              1.0|254952|          Me Him Her|\n",
      "|              1.0|178447|           Wide Open|\n",
      "|              1.0|347848|  Last Girl Standing|\n",
      "|              1.0| 86497|           Wide Open|\n",
      "|              1.0| 50942|            Creature|\n",
      "+-----------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_similarity.orderBy('cosine_similarity', ascending=False).select([\"cosine_similarity\", \"id\", \"title\"]).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "| cosine_similarity|count|\n",
      "+------------------+-----+\n",
      "|               1.0|19642|\n",
      "|0.9942500815212627|    1|\n",
      "| 0.994166116296929|    1|\n",
      "|0.9938847858651231|    1|\n",
      "|0.9935367136502573|    1|\n",
      "|0.9931548768957004|    1|\n",
      "|0.9930463355319291|    1|\n",
      "|0.9930395897125676|    1|\n",
      "|0.9928902739532759|    1|\n",
      "|0.9925960510257771|    1|\n",
      "+------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_similarity.groupby([\"cosine_similarity\"]).count().sort(\"cosine_similarity\", ascending=False).show(10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}