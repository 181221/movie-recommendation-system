{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import mean, min, max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.100.108:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd2c1a408d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_movies = spark.read.load('/home/peder/dev/big-data/movie-recommendation-system/data/movies_metadata.csv',\n",
    "                           format=\"csv\",\n",
    "                           sep=\",\",\n",
    "                           inferSchema=\"true\",\n",
    "                           header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- adult: string (nullable = true)\n",
      " |-- belongs_to_collection: string (nullable = true)\n",
      " |-- budget: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- homepage: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- imdb_id: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- overview: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- revenue: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- spoken_languages: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- tagline: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- video: string (nullable = true)\n",
      " |-- vote_average: string (nullable = true)\n",
      " |-- vote_count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movies.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is 45572 rows by 24 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the dataset is {:d} rows by {:d} columns\".format(df_movies.count(), len(df_movies.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498\n",
      "389\n",
      "985\n"
     ]
    }
   ],
   "source": [
    "print(df_movies.filter(col(\"vote_average\").isNull()).count())\n",
    "print(df_movies.filter(col(\"vote_count\").isNull()).count())\n",
    "print(df_movies.filter(col(\"overview\").isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_movies = df_movies.na.drop(subset=[\"vote_average\"])\n",
    "df_movies = df_movies.na.drop(subset=[\"vote_count\"])\n",
    "df_movies = df_movies.na.drop(subset=[\"overview\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_movies = df_movies.withColumn(\"vote_average\", df_movies[\"vote_average\"].cast(\"double\"))\n",
    "df_movies = df_movies.withColumn(\"vote_count\", df_movies[\"vote_count\"].cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_movies = df_movies.filter((df_movies.vote_average >=0) & (df_movies.vote_average<=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      vote_average|\n",
      "+-------+------------------+\n",
      "|  count|             40786|\n",
      "|   mean| 5.612511975530867|\n",
      "| stddev|1.9231620784205472|\n",
      "|    min|               0.0|\n",
      "|    max|              10.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movies.select(['vote_average']).describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|       vote_count|\n",
      "+-------+-----------------+\n",
      "|  count|            40760|\n",
      "|   mean|112.1123405299313|\n",
      "| stddev|490.1629388596058|\n",
      "|    min|                0|\n",
      "|    max|            12269|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movies.select(['vote_count']).describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|overview                                                                                                                                                                                                                                                                                                       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movies.select(['overview']).show(truncate=False, n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(df, column_name=\"content\"):\n",
    "    \"\"\"\n",
    "    This fucntion takes the raw text data and apply a standard NLP preprocessing pipeline consisting of the following steps:\n",
    "      - Text cleaning\n",
    "      - Tokenization\n",
    "      - Stopwords removal\n",
    "      - Stemming (Snowball stemmer)\n",
    "\n",
    "    parameter: dataframe\n",
    "    returns: the input dataframe along with the `cleaned_content` column as the results of the NLP preprocessing pipeline\n",
    "\n",
    "    \"\"\"\n",
    "    from pyspark.sql.functions import udf, col, lower, trim, regexp_replace, concat_ws\n",
    "    from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "    # Text preprocessing pipeline\n",
    "    print(\"***** Text Preprocessing Pipeline *****\\n\")\n",
    "\n",
    "    # 1. Text cleaning\n",
    "    print(\"# 1. Text Cleaning\\n\")\n",
    "    # 1.a Case normalization\n",
    "    print(\"1.a Case normalization:\")\n",
    "    lower_case_news_df = df.select(\"id\", lower(col(column_name)).alias(column_name))\n",
    "    lower_case_news_df.show(10)\n",
    "    # 1.b Trimming\n",
    "    print(\"1.b Trimming:\")\n",
    "    trimmed_news_df = lower_case_news_df.select(\"id\", trim(col(column_name)).alias(column_name))\n",
    "    trimmed_news_df.show(10)\n",
    "    # 1.c Filter out punctuation symbols\n",
    "    print(\"1.c Filter out punctuation:\")\n",
    "    no_punct_news_df = trimmed_news_df.select(\"id\", (regexp_replace(col(column_name), \"[^a-zA-Z\\\\s]\", \"\")).alias(column_name))\n",
    "    no_punct_news_df.show(10)\n",
    "    # 1.d Filter out any internal extra whitespace\n",
    "    print(\"1.d Filter out extra whitespaces:\")\n",
    "    cleaned_news_df = no_punct_news_df.select(\"id\", trim(regexp_replace(col(column_name), \" +\", \" \")).alias(column_name))\n",
    "\n",
    "    # 2. Tokenization (split text into tokens)\n",
    "    print(\"# 2. Tokenization:\")\n",
    "    tokenizer = Tokenizer(inputCol=column_name, outputCol=\"tokens\")\n",
    "    tokens_df = tokenizer.transform(cleaned_news_df)\n",
    "\n",
    "    print(\"# 3. Stopwords removal:\")\n",
    "    stopwords_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"terms\")\n",
    "    terms_df = stopwords_remover.transform(tokens_df)\n",
    "\n",
    "    print(\"# 4. Stemming:\")\n",
    "    stemmer = SnowballStemmer(language=\"english\")\n",
    "    stemmer_udf = udf(lambda tokens: [stemmer.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "    terms_stemmed_df = terms_df.withColumn(\"terms_stemmed\", stemmer_udf(\"terms\"))\n",
    "    \n",
    "    print(\"# 5. untokenize\")\n",
    "    terms_joined_df = terms_stemmed_df.withColumn(\"terms_join\", concat_ws(\" \", \"terms_stemmed\"))\n",
    "    return terms_joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Text Preprocessing Pipeline *****\n",
      "\n",
      "# 1. Text Cleaning\n",
      "\n",
      "1.a Case normalization:\n",
      "+-----+--------------------+\n",
      "|   id|            overview|\n",
      "+-----+--------------------+\n",
      "|  862|led by woody, and...|\n",
      "| 8844|when siblings jud...|\n",
      "|15602|a family wedding ...|\n",
      "|11862|just when george ...|\n",
      "|  949|obsessive master ...|\n",
      "|11860|an ugly duckling ...|\n",
      "|45325|a mischievous you...|\n",
      "| 9091|international act...|\n",
      "|  710|james bond must u...|\n",
      "| 9087|widowed u.s. pres...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "1.b Trimming:\n",
      "+-----+--------------------+\n",
      "|   id|            overview|\n",
      "+-----+--------------------+\n",
      "|  862|led by woody, and...|\n",
      "| 8844|when siblings jud...|\n",
      "|15602|a family wedding ...|\n",
      "|11862|just when george ...|\n",
      "|  949|obsessive master ...|\n",
      "|11860|an ugly duckling ...|\n",
      "|45325|a mischievous you...|\n",
      "| 9091|international act...|\n",
      "|  710|james bond must u...|\n",
      "| 9087|widowed u.s. pres...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "1.c Filter out punctuation:\n",
      "+-----+--------------------+\n",
      "|   id|            overview|\n",
      "+-----+--------------------+\n",
      "|  862|led by woody andy...|\n",
      "| 8844|when siblings jud...|\n",
      "|15602|a family wedding ...|\n",
      "|11862|just when george ...|\n",
      "|  949|obsessive master ...|\n",
      "|11860|an ugly duckling ...|\n",
      "|45325|a mischievous you...|\n",
      "| 9091|international act...|\n",
      "|  710|james bond must u...|\n",
      "| 9087|widowed us presid...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "1.d Filter out extra whitespaces:\n",
      "# 2. Tokenization:\n",
      "# 3. Stopwords removal:\n",
      "# 4. Stemming:\n",
      "# 5. untokenize\n"
     ]
    }
   ],
   "source": [
    "df_clean = clean_text(df_movies, 'overview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|terms_stemmed                                                                                                                                                                                                                     |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[led, woodi, andi, toy, live, happili, room, andi, birthday, bring, buzz, lightyear, onto, scene, afraid, lose, place, andi, heart, woodi, plot, buzz, circumst, separ, buzz, woodi, owner, duo, eventu, learn, put, asid, differ]|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.select('terms_stemmed').show(truncate=False, n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|terms_join                                                                                                                                                                                                                      |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|led woodi andi toy live happili room andi birthday bring buzz lightyear onto scene afraid lose place andi heart woodi plot buzz circumst separ buzz woodi owner duo eventu learn put asid differ                                |\n",
      "|sibl judi peter discov enchant board game open door magic world unwit invit alan adult whos trap insid game year live room alan hope freedom finish game prove riski three find run giant rhinoceros evil monkey terrifi creatur|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.select('terms_join').show(truncate=False, n=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, CountVectorizer, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"terms_stemmed\", outputCol=\"tf_features\", vocabSize=2000, minDF=10)\n",
    "idf = IDF(inputCol=\"tf_features\", outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[cv, idf])\n",
    "features = pipeline.fit(df_clean)\n",
    "tf_idf_features_df = features.transform(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(\"long\")\n",
    "def num_nonzeros(v):\n",
    "    return v.numNonzeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total n. of zero-length vectors: 38\n"
     ]
    }
   ],
   "source": [
    "print(\"Total n. of zero-length vectors: {:d}\".\n",
    "      format(tf_idf_features_df.where(num_nonzeros(\"features\") == 0).count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_features_df = tf_idf_features_df.where(num_nonzeros(\"features\") > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total n. of zero-length vectors (after removal): 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total n. of zero-length vectors (after removal): {:d}\".\n",
    "      format(tf_idf_features_df.where(num_nonzeros(\"features\") == 0).count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40748"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_features_df.select('features').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = tf_idf_features_df.select(col(\"features\")).first()\n",
    "df_b = tf_idf_features_df.select(col(\"features\")).take(2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666635763568375"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cosine_similarity_test(a, b):\n",
    "    return 1 - a.dot(b)/(a.norm(2)*b.norm(2))\n",
    "cosine_similarity_test(df_a.features, df_b.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
